\subsection*{Problem 1.3}
Let $x = (x_1, \ldots , x_n)$ be in $\{0,1\}^n$ and let
\begin{align*}
	f:\{0,1\}^n &\rightarrow \{0,1\}\\
		x&\mapsto f(x)
\end{align*}
be any boolean function.

\paragraph{Claim}
$f$ can be represented in Disjunctive Normal Form (DNF).

\paragraph{Proof}
We can easily see that any $x\in\{0,1\}^n$ can be expressed uniquely as a conjunctive clause. 
Therefore we define the mapping:
\begin{align*}
	c(x) &:= \bigwedge _{i=1}^{n}\tilde{c}({x}_ i)
\end{align*}
with
\begin{align*}
\tilde{c}({x}_ i) := 
\begin{cases} 
	q _i &\mbox{if } x _i = 1 \\ 
	!q _i & \mbox{if } x _i = 0. 
\end{cases} 
\end{align*}
First let us label any $x\in\{0,1\}^n$ with their decimal equivalent, i.e.
$x = (x_1, \ldots , x_n)=: x^{(k)}$ if $k = \sum _{i=0}^{n-1} x_{i+1}2^{n-1-i}$.\\
Let $f$ be arbitrary but fixed and define
\begin{align*}
	M:= \{x\in\{0,1\}^n | f(x)=1 \} \subset \{0,1\}^n
\end{align*}
Now again let us label the elements in $M$ bijectively.
For this purpose we can define a label function 
\begin{align*}
	g:M \rightarrow N\subset \mathbb{N}\\
	x^{(k)} \mapsto g(x^{(k)}):= k
\end{align*} 
Lastly we define a function, that applies the $k$-th conjunctive clause to any arbitary $x\in\{0,1\}^n$:
\begin{align*}
	h(x,k):= \bigwedge _{i=1}^{n}\tilde{h}({x}_ i,k)
\end{align*}
with
\begin{align*}
\tilde{h}({x}_ i,k) := 
\begin{cases} 
	x_i &\mbox{if } \tilde{c}(x _i^{(k)}) = q_i^{(k)} \\ 
	1-x_i & \mbox{if }\tilde{c}(x _i^{(k)}) = !q_i^{(k)} . 
\end{cases} 
\end{align*}
It is now easy to see, that $f$ is identical to the following definition:
\begin{align*}
	f(x) =  \bigvee _{k\in g(M)} h(x,k) 
\end{align*}
Thus $f$ has a representation in DNF.

\paragraph{Claim}
Any boolean function in DNF can be calculated by means of a 2 layer perceptron.

\paragraph{Proof}
First we prove that any conjunctive clause can be calculated by a 1 layer perceptron.\\
Let $t = q_1 \wedge \ldots \wedge q_n$ be a conjunctive clause and $x\in\{0,1\}^n$ the input vector. Now formulate the inequality:
\begin{align}
	X_1 + X_2 + \ldots +X_n \geq n -\epsilon
	\label{eq1}
\end{align}
with $\epsilon > 0$ and
\begin{align*}
X_i := 
\begin{cases} 
	x _i &\mbox{if } x_i = q_i  \\ 
	1-x _i &\mbox{if } x_i = !q_i
\end{cases} 
\end{align*}
Now (\ref{eq1}) can be easily rearranged to an inequation of the form:
\begin{align*}
	w_0 + w_1x_1 + \ldots + w_nx_n \geq 0
\end{align*}
Now we prove that any disjunctive clause can be calculated by a 1 layer perceptron.\\
Let $t = q_1 \vee \ldots \vee q_n$ be a disjunctive clause and $x\in\{0,1\}^n$ the input vector. Now formulate the inequality:
\begin{align}
X_1 + X_2 + \ldots +X_n \geq \epsilon
\label{eq2}
\end{align}
with $\epsilon > 0$ and
\begin{align*}
X_i := 
\begin{cases} 
	x _i &\mbox{if } x_i = q_i  \\ 
	1-x _i &\mbox{if } x_i = !q_i
\end{cases} 
\end{align*}
Now (\ref{eq2}) can be easily rearranged to an inequation of the form:
\begin{align*}
	w_0 + w_1x_1 + \ldots + w_nx_n \geq 0
\end{align*}
With these observations we can now conclude that any boolean function in DNF (and even CNF) can be calculated by only 2 layers.
(first layer handling the conjunctive clauses and 2nd layer handling the results of the first layer in disjunctive manner, for CNF vice verca).
Thus every boolean function can be represented by a 2 layer network.
